{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Callbacks.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Javcm/Temas-selectos-de-Ciencia-de-Datos-Ayudantias-CIMAT/blob/main/Callbacks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4bwGriBUwx0"
      },
      "source": [
        "# Callbacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaqxtEDKUwx1"
      },
      "source": [
        "https://keras.io/api/callbacks/\n",
        "\n",
        "* **Model checkpointing** : Guarda los pesos actuales del modelo en diferentes puntos del entrenamiento\n",
        "\n",
        "\n",
        "* **Early stopping**: Interrumpe el entrenamiento cuando el error de validación no mejora (guarda el mejor modelo obtenido en el entrenamiento)\n",
        "\n",
        "* **ReduceLROnPlateau**: Reduce el learning rate cuando el entrenamiento ha dejado de mejorar.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsKj6RctUwx4",
        "outputId": "41e189f3-51ed-4766-f8d8-7611756f0a6f"
      },
      "source": [
        "import keras\n",
        "keras.callbacks.ModelCheckpoint\n",
        "keras.callbacks.EarlyStopping\n",
        "keras.callbacks.ReduceLROnPlateau\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "keras.callbacks.CSVLogger"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S27ESlfYUwx8"
      },
      "source": [
        "**THE MODELCHECKPOINT AND EARLYSTOPPING CALLBACKS**\n",
        "\n",
        "* **EarlyStopping callback:** interrumpe el entrenamiento una vez que la metrica a monitorear deja de mejorar para un número fijo de epocas. Permite detener el entrenamiento antes de presentar problemas de overfitting\n",
        "\n",
        "\n",
        "* **ModelCeckpoint**: permite guardr continuamente el modelo durante el entrenamiento (sólo guarda el mejor modelo: el modelo que registra la mejor actuación al final de cada epoca)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BunEb9rWUwx_"
      },
      "source": [
        "import keras\n",
        "\n",
        "#Los Callbacks se pasan como argumento en forma de lista en el entrenamiento (en el .fit)\n",
        "\n",
        "callbacks_list = [keras.callbacks.EarlyStopping(monitor='acc', patience=10,), # Interrumpe entrenamiento cuando no hay mejora\n",
        "                  \n",
        "                  # monitor -> Parámetro a monitorear en la validación del modelo.\n",
        "                  # patience -> Número a partir del cuál se interrumpe el entrenamiento cuando la métrica no mejora.\n",
        "                  \n",
        "                  keras.callbacks.ModelCheckpoint(filepath='my_model.h5', monitor='val_loss', save_best_only=True,)] # Saves the current weights after every epoch\n",
        "                # filepath -> Dirección a guardar del modelo\n",
        "                # monitor & save_best_only ->  Se guarda el modelo sólo si el error de validación mejora.        \n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "# Note that because the callback will monitor validation loss and validation accuracy, you need to pass validation_data to the call to fit.\n",
        "model.fit(X_train, Y_train, epochs=10, batch_size=32, callbacks=callbacks_list, validation_data=(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0FlpTlLUwyD"
      },
      "source": [
        "**THE REDUCELRONPLATEAU CALLBACK**\n",
        "\n",
        "* Reduce el learnig rate cuando el error de validación no mejora. Es una estrategia efectiva para salir de mínimos locales durante el entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yHNanVGUwyG"
      },
      "source": [
        "callbacks_list = [\n",
        "keras.callbacks.ReduceLROnPlateau(\n",
        "monitor='val_loss', # Monitorea el error de validación del modelo\n",
        "factor=0.1, # Divide la tasa de aprendizaje por 10 cuando se activa\n",
        "patience=2, # El callback se activa a partir de que el error de validación deja de mejorar durante 2 epocas\n",
        ")\n",
        "]\n",
        "\n",
        "\n",
        "model.fit(X_train, Y_train,\n",
        "epochs=10,\n",
        "batch_size=32,\n",
        "callbacks=callbacks_list,\n",
        "validation_data=(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruRPW4PTqmy8"
      },
      "source": [
        "class BaseLogger: Callback that accumulates epoch averages of metrics.\n",
        "\n",
        "class CSVLogger: Callback that streams epoch results to a CSV file.\n",
        "\n",
        "class Callback: Abstract base class used to build new callbacks.\n",
        "\n",
        "class CallbackList: Container abstracting a list of callbacks.\n",
        "\n",
        "class EarlyStopping: Stop training when a monitored metric has stopped improving.\n",
        "\n",
        "class History: Callback that records events into a History object.\n",
        "\n",
        "class LambdaCallback: Callback for creating simple, custom callbacks on-the-fly.\n",
        "\n",
        "class LearningRateScheduler: Learning rate scheduler.\n",
        "\n",
        "class ModelCheckpoint: Callback to save the Keras model or model weights at some frequency.\n",
        "\n",
        "class ProgbarLogger: Callback that prints metrics to stdout.\n",
        "\n",
        "class ReduceLROnPlateau: Reduce learning rate when a metric has stopped improving.\n",
        "\n",
        "class RemoteMonitor: Callback used to stream events to a server.\n",
        "\n",
        "class TensorBoard: Enable visualizations for TensorBoard.\n",
        "\n",
        "class TerminateOnNaN: Callback that terminates training when a NaN loss is encountered."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bD_FrYj4UwyT"
      },
      "source": [
        "Ejemplo: Clasificación de Texto con TensorBoard\n",
        "\n",
        "Datos -> IMDB data análisis de sentimientos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkePhK6eglaL",
        "outputId": "b3e0b335-6ae8-47cf-a902-76cfce60bc8d"
      },
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "from keras.preprocessing import sequence\n",
        "import numpy as np\n",
        "from keras.datasets import imdb\n",
        "\n",
        "\n",
        "max_features = 2000\n",
        "max_len = 500\n",
        "\n",
        "(X_train, Y_train), (X_test, Y_test) = imdb.load_data()\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_len)\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(layers.Embedding(max_features, 128,input_length=max_len,name='embed'))\n",
        "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
        "model.add(layers.MaxPooling1D(5))\n",
        "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
        "model.add(layers.GlobalMaxPooling1D())\n",
        "model.add(layers.Dense(1))\n",
        "model.summary()\n",
        "model.compile(optimizer='rmsprop',\n",
        "loss='binary_crossentropy',\n",
        "metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embed (Embedding)            (None, 500, 128)          256000    \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 494, 32)           28704     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 98, 32)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 92, 32)            7200      \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_2 (Glob (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 291,937\n",
            "Trainable params: 291,937\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}